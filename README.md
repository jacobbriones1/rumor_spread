
# ğŸ“£ Rumor Spread Modeling with FNOs

A research simulation and machine learning pipeline for modeling **rumor propagation dynamics** using **Fourier Neural Operators (FNOs)**. Based on a modular design, this framework supports:

- Forward simulations of rumor dynamics
- Inverse parameter recovery (learning model parameters from data)
- Neural operator learning with PyTorch

---

## ğŸš€ Features

- âœ… Modular simulation engine (Dong Model, SIR, etc.)
- ğŸ“Š Data generation with configurable sampling
- ğŸ§  Fourier Neural Operator for time-series learning
- ğŸ” Forward & inverse training pipelines
- ğŸ“ˆ Inference and visualization utilities
- ğŸ’ª Parameter Sensitivity and Bifurcation Analysis

## ğŸ§¬ Model Summary

### Modular Dynamical Systems Framework

This project is structured as a **modular simulator-learner pipeline** using modern Python best practices. At the core is an abstract modeling interface, designed to allow **pluggable, interchangeable dynamical systems**, which can be trained and analyzed using Fourier Neural Operators (FNOs).

#### ğŸ”§ Core Design Pattern: Abstract Base Class

- `DynamicalSystem` in `dynamics/base.py` defines the contract all models must follow:
  - `.simulate(params, T, dt, **kwargs)`
  - `.parameter_dim()` and `.state_dim()`

This enables seamless compatibility with the learning pipeline, regardless of model type.

#### ğŸš€ Model Implementations

- `DongRumorModel` (in `dynamics/dong_model.py`) implements a deterministic, discrete-time rumor spread system
- `SIRModel` (in `dynamics/sir_model.py`) simulates epidemics over a network topology
- More models can be added with just a few lines by subclassing `DynamicalSystem`

#### ğŸ§  Learning Pipeline (Forward/Inverse)

- `models/fno.py` implements the Fourier Neural Operator (`FNO1d`) using spectral layers (`spectral_conv.py`)
- Input/output format for models is unified: `[batch, channels, time]`
- `run_pipeline.py` controls CLI workflows: `train_forward`, `train_inverse`, and `inference`

#### ğŸ§ª Utilities

- `utils/data_generation.py` handles dataset creation with time-grid embedding
- Modular design means data generation is **model-agnostic**

#### ğŸ§µ Scripts

- `scripts/train_forward.py` and `scripts/train_inverse.py` are standalone versions of the training loops
- These scripts help debug and iterate quickly, decoupled from CLI interface

#### ğŸ“¦ Structure Overview

- `dynamics/`
  - `base.py` â€” Defines abstract base class `DynamicalSystem`
  - `dong_model.py` â€” Dong rumor model subclassing `DynamicalSystem`
  - `sir_model.py` â€” Network-based SIR model (partially implemented)
- `models/`
  - `fno.py` â€” Defines the core `FNO1d` model using SpectralConv1d blocks
  - `spectral_conv.py` â€” Implements the 1D spectral convolution layer
- `utils/`
  - `data_generation.py` â€” Unified dataset creation function with time-aware formatting
- `scripts/`
  - `train_forward.py` â€” Trains FNO on trajectories generated by a system
  - `train_inverse.py` â€” Trains FNO to recover parameters from system dynamics
- `run_pipeline.py` â€” Command-line entrypoint to run end-to-end pipelines
- `inference.py` â€” Standalone script to evaluate a trained FNO model on a known system

## ğŸ§ª Example Usage

### Train Forward Model
```bash
python run_pipeline.py train_forward --epochs 100
```

### Train Inverse Model
```bash
python run_pipeline.py train_inverse --epochs 100
```

### Run Full Pipeline
```bash
python run_pipeline.py all --epochs 100
```

### Visualize Predictions
```bash
python run_pipeline.py inference
```


## ğŸ›  Requirements

- Python 3.10+
- PyTorch â‰¥ 1.12
- matplotlib
- tqdm
- numpy
- networkx (for SIR graph models)

Install everything:
```bash
pip install -r requirements.txt
```


## ğŸ¤ Contributing

PRs and ideas welcome! Open an issue or fork the project and drop some ğŸ”¥ improvements.

## ğŸ§  Author

**Jacob Briones**  
Feel free to connect or cite the project!

## ğŸ“œ License

MIT License
