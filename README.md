
# 📣 Rumor Spread Modeling with FNOs

A research simulation and machine learning pipeline for modeling **rumor propagation dynamics** using **Fourier Neural Operators (FNOs)**. Based on a modular design, this framework supports:

- Forward simulations of rumor dynamics
- Inverse parameter recovery (learning model parameters from data)
- Neural operator learning with PyTorch

---

## 🚀 Features

- ✅ Modular simulation engine (Dong Model, SIR, etc.)
- 📊 Data generation with configurable sampling
- 🧠 Fourier Neural Operator for time-series learning
- 🔁 Forward & inverse training pipelines
- 📈 Inference and visualization utilities
- 💪 Parameter Sensitivity and Bifurcation Analysis

## 🧬 Model Summary

### Modular Dynamical Systems Framework

This project is structured as a **modular simulator-learner pipeline** using modern Python best practices. At the core is an abstract modeling interface, designed to allow **pluggable, interchangeable dynamical systems**, which can be trained and analyzed using Fourier Neural Operators (FNOs).

#### 🔧 Core Design Pattern: Abstract Base Class

- `DynamicalSystem` in `dynamics/base.py` defines the contract all models must follow:
  - `.simulate(params, T, dt, **kwargs)`
  - `.parameter_dim()` and `.state_dim()`

This enables seamless compatibility with the learning pipeline, regardless of model type.

#### 🚀 Model Implementations

- `DongRumorModel` (in `dynamics/dong_model.py`) implements a deterministic, discrete-time rumor spread system
- `SIRModel` (in `dynamics/sir_model.py`) simulates epidemics over a network topology
- More models can be added with just a few lines by subclassing `DynamicalSystem`

#### 🧠 Learning Pipeline (Forward/Inverse)

- `models/fno.py` implements the Fourier Neural Operator (`FNO1d`) using spectral layers (`spectral_conv.py`)
- Input/output format for models is unified: `[batch, channels, time]`
- `run_pipeline.py` controls CLI workflows: `train_forward`, `train_inverse`, and `inference`

#### 🧪 Utilities

- `utils/data_generation.py` handles dataset creation with time-grid embedding
- Modular design means data generation is **model-agnostic**

#### 🧵 Scripts

- `scripts/train_forward.py` and `scripts/train_inverse.py` are standalone versions of the training loops
- These scripts help debug and iterate quickly, decoupled from CLI interface

#### 📦 Structure Overview

- `dynamics/`
  - `base.py` — Defines abstract base class `DynamicalSystem`
  - `dong_model.py` — Dong rumor model subclassing `DynamicalSystem`
  - `sir_model.py` — Network-based SIR model (partially implemented)
- `models/`
  - `fno.py` — Defines the core `FNO1d` model using SpectralConv1d blocks
  - `spectral_conv.py` — Implements the 1D spectral convolution layer
- `utils/`
  - `data_generation.py` — Unified dataset creation function with time-aware formatting
- `scripts/`
  - `train_forward.py` — Trains FNO on trajectories generated by a system
  - `train_inverse.py` — Trains FNO to recover parameters from system dynamics
- `run_pipeline.py` — Command-line entrypoint to run end-to-end pipelines
- `inference.py` — Standalone script to evaluate a trained FNO model on a known system

## 🧪 Example Usage

### Train Forward Model
```bash
python run_pipeline.py train_forward --epochs 100
```

### Train Inverse Model
```bash
python run_pipeline.py train_inverse --epochs 100
```

### Run Full Pipeline
```bash
python run_pipeline.py all --epochs 100
```

### Visualize Predictions
```bash
python run_pipeline.py inference
```


## 🛠 Requirements

- Python 3.10+
- PyTorch ≥ 1.12
- matplotlib
- tqdm
- numpy
- networkx (for SIR graph models)

Install everything:
```bash
pip install -r requirements.txt
```


## 🤝 Contributing

PRs and ideas welcome! Open an issue or fork the project and drop some 🔥 improvements.

## 🧠 Author

**Jacob Briones**  
Feel free to connect or cite the project!

## 📜 License

MIT License
