# ğŸ§  Rumor Propagation with Modular Fourier Neural Operators

This repo simulates and learns the dynamics of **rumor spreading** on networks using **Fourier Neural Operators (FNOs)**.

The system is modular, interpretable, and frequency-aware â€” enabling both forward modeling and inverse parameter inference, with interpretable insights into learned frequency modes.

---

## ğŸ“¦ Features

- âœ… Simulate rumor dynamics on ER, BA, WS graphs
- âœ… Train **FNOs** to learn time evolution of SIR systems
- ğŸ” Invert trajectories â†’ model parameters with inverse FNOs
- ğŸ“ˆ Bifurcation surface generation over Î±, Î², Î´ parameter sweeps
- ğŸ§  Visualize learned **spectral filters** and frequency preferences
- ğŸ” Explore effect of network topology on rumor behavior

---

## ğŸ§¬ Models Included

Each model implements:

```python
.simulate(params, T, dt, ...)
.parameter_dim()
.state_dim()
```

### ğŸ”¹ `DongRumorModel`  
ODE-based SIR-type model from Dong et al. (2018)

### ğŸ”¹ `SIRModel`  
Standard SIR rumor model on fixed graph topologies

### ğŸ”¹ `DegreeAwareSIRModel`  
Agent-based SIR model using degree-dependent transition probabilities \( P(k'|k) \) â€” now supports FNO-based learning and full parameter inversion

---

## ğŸ“‚ Project Structure

```
modular_fno/
â”œâ”€â”€ dynamics/               # Simulation models
â”œâ”€â”€ models/                 # FNO + spectral conv layers
â”œâ”€â”€ scripts/                # Training, visualization, spectral analysis
â”œâ”€â”€ utils/                  # Dataset generation, normalization
â”œâ”€â”€ run_pipeline.py         # Unified forward + inverse training CLI
â”œâ”€â”€ data/                   # Saved datasets
â”œâ”€â”€ checkpoints/            # Trained model weights
```

---

## ğŸ”§ Training & Inference

### Forward Training (params â†’ trajectory)
```bash
python run_pipeline.py train_forward --epochs 50
```

### Inverse Training (trajectory â†’ params)
```bash
python run_pipeline.py train_inverse --epochs 50
```

### Full Pipeline
```bash
python run_pipeline.py all --epochs 50
```

---

## ğŸ¨ Spectral Visualizations

Learned spectral filters are interpretable and can be visualized:

### ğŸ”¹ Fourier Filter Line Plots
```bash
python scripts/visualize_fourier_filters.py   --checkpoint checkpoints/fno_forward_heterogeneous.pth   --in_channels 5 --out_channels 3
```

### ğŸ”¹ Filter Matrix View (per layer, per input/output channel pair)
```bash
python scripts/visualize_filter_matrices.py
```

### ğŸ”¹ Aggregated Frequency Spectrum
```bash
python scripts/plot_aggregated_spectrum.py   --checkpoint checkpoints/fno_forward_heterogeneous.pth   --in_channels 5 --out_channels 3
```

This reveals which Fourier modes each FNO layer focuses on â€” showing how early layers capture global dynamics and later layers refine fine-grain variations.

---

## ğŸ’¾ Data Format

Saved datasets in `data/` follow this format:
- `.pth` files with `[x_tensor, y_tensor]`
- Forward mode: `x = [params + time]`, `y = trajectory`
- Inverse mode: `x = [trajectory + time]`, `y = params`

---

## ğŸ“Š Requirements

```bash
pip install -r requirements.txt
```

- Python â‰¥ 3.10
- PyTorch â‰¥ 1.12
- matplotlib, numpy, tqdm, seaborn, networkx

---

## âš¡ Future Extensions

- [ ] Topology-aware inverse learning (graph statistics â†’ trajectory)
- [ ] Transformer-style operator on graph signals
- [ ] Live interactive bifurcation sliders
- [ ] Compare learned filters across graph types (ER vs BA vs WS)

---

## ğŸ‘¨â€ğŸ”¬ Author

**Jacob Briones**  
Applied mathematician, neural operator whisperer, and full-time dad. Essentially self taught.
